{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efe2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Need this for some of the helper functions\n",
    "\n",
    "import torch as t\n",
    "\n",
    "# Some nice preliminary functions for testing.\n",
    "\n",
    "def assert_with_expect(expected, actual):\n",
    "    assert expected == actual, f\"Expected: {expected} Actual: {actual}\"\n",
    "\n",
    "\n",
    "def assert_list_of_floats_within_epsilon(\n",
    "    expected: list[float], \n",
    "    actual: list[float],\n",
    "    eps=0.0001,\n",
    "):\n",
    "    if len(expected) != len(actual):\n",
    "        raise AssertionError(f\"Expected: {expected} Actual: {actual}\")\n",
    "    is_within_eps = True\n",
    "    for e, a in zip(expected, actual):\n",
    "        is_within_eps = is_within_eps and abs(e - a) < eps\n",
    "    if not is_within_eps:\n",
    "        raise AssertionError(f\"Expected: {expected} Actual: {actual}\")\n",
    "\n",
    "\n",
    "def assert_tensors_within_epsilon(\n",
    "    expected: t.Tensor,\n",
    "    actual: t.Tensor,\n",
    "    eps=0.001,\n",
    "):\n",
    "    if expected.shape != actual.shape:\n",
    "        raise AssertionError(f\"Shapes of tensors do not match! Expected: {expected.shape} Acutal: {actual.shape}\")\n",
    "    differences_within_epsilon = abs(expected - actual) < eps\n",
    "    if not differences_within_epsilon.all():\n",
    "        raise AssertionError(f\"Values of tensors do not match! Expected: {expected} Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bff4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We're going to begin by defining neural networks in a way that emphasizing\n",
    "# each individual neuron. This is very inefficient and impractical for any real\n",
    "# neural network (at least in Python). Also by thinking at the individual neuron\n",
    "# level, this obscures a lot of larger structures in a neural net that can\n",
    "# actually make it more difficult to understand what's going on at a high-level.\n",
    "#\n",
    "# Nonetheless, it's a reasonable starting point for understanding why we call a\n",
    "# neural net \"neural.\" We'll redo our neural net using matrices later in this\n",
    "# section to demonstrate how they're actually written \"in the wild.\"\n",
    "#\n",
    "# Let's begin by defining one of the simplest non-linear activation functions\n",
    "# out there. We'll need this as the last step of computation when defining what\n",
    "# a single neuron does.\n",
    "\n",
    "def relu(x: float) -> float:\n",
    "    \"\"\"\n",
    "    ReLU (rectified linear unit), one of the simplest non-linear activation\n",
    "    functions out there.\n",
    "    \"\"\"\n",
    "    # TODO: Fill this in!\n",
    "    return max(0, x)\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "assert_with_expect(expected=5.0, actual=relu(5.0))\n",
    "assert_with_expect(expected=0.0, actual=relu(-1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef68420",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# Now let's define a single neuron. If you want a reminder of how a single\n",
    "# neuron is structured, look at\n",
    "# https://github.com/changlinli/intro-to-technical-ai-safety-slides/blob/master/neural_nets/slides.md#a-single-neuron-also-called-node\n",
    "# (note that the diagram is a bit misleading w.r.t. bias, bias isn't always +1,\n",
    "# it can be + some other constant!).\n",
    "#\n",
    "# For now don't worry about using tensors to carry this out, normal Python\n",
    "# iteration is perfectly fine.\n",
    "\n",
    "@dataclass\n",
    "class Neuron:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    weights: list[float]\n",
    "    bias: float\n",
    "\n",
    "    def compute_output(self, inputs: list[float]) -> float:\n",
    "        \"\"\"\n",
    "        Compute what the output of a single neuron should look like.\n",
    "        \"\"\"\n",
    "        assert len(inputs) == len(self.weights)\n",
    "        # TODO: Fill this in!\n",
    "        # raise NotImplementedError()\n",
    "        mult = t.mul(t.Tensor(inputs), t.Tensor(self.weights))\n",
    "        neuron_out = t.sum(mult) + self.bias\n",
    "        return relu(neuron_out)\n",
    "\n",
    "test_neuron = Neuron(weights=[1, 2], bias=0.5)\n",
    "assert_with_expect(actual=test_neuron.compute_output([2, 3]), expected=8.5)\n",
    "assert_with_expect(actual=test_neuron.compute_output([2, -2]), expected=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b3a5ff",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now let's define a forward pass for a single layer of neurons. Note that every\n",
    "# neuron must have the same number of inputs (as determined by the number of\n",
    "# weights) and it must match the number of inputs coming into the layer.\n",
    "\n",
    "def forward_pass_single_layer(input: list[float], layer: list[Neuron]) -> list[float]:\n",
    "    layer_output = []\n",
    "    for neuron in layer:\n",
    "        assert len(neuron.weights) == len(input)\n",
    "        # TODO: Fill this in!\n",
    "        # raise NotImplementedError()\n",
    "        layer_output.append(neuron.compute_output(input))\n",
    "    return layer_output\n",
    "\n",
    "test_layer = [\n",
    "    Neuron(weights=[0.1, 0.2], bias=0.3),\n",
    "    Neuron(weights=[-0.15, 0.1], bias=-0.1),\n",
    "    Neuron(weights=[0.2, 0.1], bias=0.1),\n",
    "]\n",
    "assert_list_of_floats_within_epsilon(\n",
    "    actual=forward_pass_single_layer(input=[5.5, 1.2], layer=test_layer),\n",
    "    expected=[1.09, 0.0, 1.32],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d235a77",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now let's take `forward_pass_single_layer` and use it to perform a single\n",
    "# forward pass over an entire network with multiple layers.\n",
    "\n",
    "def forward_pass_network(initial_inputs: list[float], layers: list[list[Neuron]]) -> list[float]:\n",
    "    last_output = initial_inputs\n",
    "    for layer in layers:\n",
    "        last_output = forward_pass_single_layer(last_output, layer)\n",
    "    return last_output\n",
    "\n",
    "\n",
    "# The following is an example of a neural net that takes in two inputs and has\n",
    "# two outputs, and has three layers: 3 neurons, 2 neurons, and 2 neurons\n",
    "# Notice that:\n",
    "#   1. Because we take in two inputs, the first layer of neurons all have two weights\n",
    "#   2. Because there are three neurons that feed into the second layer, all the neurons of the second layer have three\n",
    "#      weights\n",
    "#   3. Because there are two neurons in the second layer, all the neurons of the third layer have two weights\n",
    "#   4. We have three inputs and two outputs because the first layer has three neurons and the last layer has two neurons\n",
    "demo_network: list[list[Neuron]] = \\\n",
    "    [\n",
    "        [\n",
    "            Neuron(weights=[0.1, 0.2], bias=0.3),\n",
    "            Neuron(weights=[-0.15, 0.1], bias=-0.1),\n",
    "            Neuron(weights=[0.2, 0.1], bias=0.1),\n",
    "        ],\n",
    "        [\n",
    "            Neuron(weights=[0.1, 0.2, 0.3], bias=0.3),\n",
    "            Neuron(weights=[-0.15, 0.1, 0.9], bias=-0.1),\n",
    "        ],\n",
    "        [\n",
    "            Neuron(weights=[0.1, 0.2], bias=0.3),\n",
    "            Neuron(weights=[-0.15, 0.1], bias=-0.1),\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "\n",
    "assert_list_of_floats_within_epsilon(\n",
    "    expected=[0.342, 0.0],\n",
    "    actual=forward_pass_network([0.0, 1.0], demo_network),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1048b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We could do backpropagation manually by writing out the chain rule by hand to\n",
    "# calculate each derivative. This is extremely tedious and no one does this. It\n",
    "# makes it extremely difficult to experiment with different neural nets because\n",
    "# we have to manually rederive all our derivatives each time.\n",
    "#\n",
    "# Instead ML practitioners always use some library that provides\n",
    "# autodifferentiation (also sometimes called autograd). In our case, that will\n",
    "# be PyTorch. Hence in the interests of time we'll skip writing out\n",
    "# backpropagation for our network here.\n",
    "#\n",
    "# You'll dive more into the internals of how backpropagation works when we\n",
    "# reimplement PyTorch's autodifferentiation feature.\n",
    "\n",
    "def backpropagation(network: list[list[Neuron]]):\n",
    "    # Don't worry about implementing this\n",
    "    raise NotImplementedError(\"This is too tedious to implement.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67b089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b9073ac170>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch as t\n",
    "from jaxtyping import Float\n",
    "\n",
    "# Just to make sure our results are reproducible\n",
    "t.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da1cc827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad=tensor([11.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Here's an example of using PyTorch to automatically calculate a derivative for\n",
    "# you. When we are manually creating tensors, we have to explicitly tell PyTorch\n",
    "# to remember we want to calculate the gradient for this tensor, so we should\n",
    "# pass in requires_grad=True. As we use PyTorch more and more, we'll see a lot\n",
    "# of library calls that will automatically take care of this for us.\n",
    "#\n",
    "# All of PyTorch's functions that work on tensors keep track of which operations\n",
    "# have performed on which tensors in what PyTorch calls a \"computational graph.\"\n",
    "# It is this computational graph that allows PyTorch to automatically calculate\n",
    "# derivatives for us.\n",
    "x = t.tensor([5.0], requires_grad=True)\n",
    "\n",
    "# Derivative here is 2x + 1, so that should be a derivative of 11 for x = 5\n",
    "y = x ** 2 + x\n",
    "\n",
    "# PyTorch's auto-differentiation facilities are based entirely around mutability\n",
    "# Make sure that you call `.backward()` before you look at the gradients!\n",
    "# Otherwise the gradients will not be set.\n",
    "#\n",
    "# Note that you call the `.backward()` method on your final derived value to get\n",
    "# the gradient/derivative of one of your input variables. That is, in order to\n",
    "# get the value of dy/dx for any y and x, you must call `.backward()` on `y` to\n",
    "# first calculate all the derivatives through the computational graph and then\n",
    "# `.grad` on `x`.\n",
    "y.backward()\n",
    "\n",
    "# x.grad is the numeral calculation of dy/dx at x = 5\n",
    "#\n",
    "# We see that the derivative is indeed 11 as we calculated by hand.\n",
    "print(f\"{x.grad=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ddf78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = t.tensor([5.0], requires_grad=True)\n",
    "\n",
    "b = t.tensor([3.0], requires_grad=True)\n",
    "\n",
    "c = a ** 2 + b ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae2db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's move on to a multivariate case.  Use PyTorch to calculate what dc/da is\n",
    "# and what dc/db are.\n",
    "\n",
    "# TODO: Fill in the Nones!\n",
    "# Remember to first populate the gradients before calling .grad!\n",
    "c.backward()\n",
    "dc_da = a.grad\n",
    "\n",
    "assert_with_expect(expected=t.tensor(10.0), actual=dc_da)\n",
    "\n",
    "dc_db = b.grad\n",
    "\n",
    "assert_with_expect(expected=t.tensor(6.0), actual=dc_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e97376ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Like almost everything else in PyTorch, autodifferentiation works with\n",
    "# multidimensional tensors as well, not just scalar values! Here's a way we\n",
    "# could calculate a and b \"at once\" in a single tensor.\n",
    "\n",
    "a_and_b = t.tensor([5.0, 3.0], requires_grad=True)\n",
    "\n",
    "c = (a_and_b ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "575ad5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use PyTorch to calculate again what dc/da and what dc/db are\n",
    "\n",
    "# TODO: Fill in the Nones!\n",
    "# Remember to first populate the gradients before calling .grad!\n",
    "c.backward()\n",
    "dc_da = a_and_b.grad[0]\n",
    "\n",
    "dc_db = a_and_b.grad[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c02fac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_input.grad=tensor([10.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If you construct different computational graphs that involve the same set of\n",
    "# input tensors and `.backward()` is called each time (so that each input tensor\n",
    "# has had the result of `.backward()` flow through multiple times), gradients\n",
    "# will \"accumulate.\" For our purposes this is usually undesirable.\n",
    "#\n",
    "# Let's go over what that means and how to avoid this.  First let's create\n",
    "# tensors as usual.\n",
    "\n",
    "some_input = t.tensor([1.0], requires_grad=True)\n",
    "\n",
    "some_output = 10 * some_input\n",
    "\n",
    "some_output.backward()\n",
    "\n",
    "# Normally because this is just y = 10 * x, we would expect the x's gradient to\n",
    "# be 10 at this point. And indeed it is.\n",
    "\n",
    "print(f\"{some_input.grad=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "086f6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch was smart enough to blow up and prevent us from going backward again with the following message:\n",
      "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PyTorch is smart enough to warn us if we try to use backward again\n",
    "\n",
    "try:\n",
    "    some_output.backward()\n",
    "except RuntimeError as e:\n",
    "    print(f\"PyTorch was smart enough to blow up and prevent us from going backward again with the following message:\\n{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f9917dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_input.grad=tensor([15.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# But PyTorch doesn't warn us if we create a new output that reuses `some_input`\n",
    "# and instead will just keep adding more gradients to the pre-existing gradient.\n",
    "# This is known as \"accumulating gradients,\" and there are reasons you might\n",
    "# want to do this, but for our purposes, this is undesirable, as it will give us\n",
    "# the wrong derivatives/gradients.\n",
    "\n",
    "another_output = 5 * some_input\n",
    "\n",
    "another_output.backward()\n",
    "\n",
    "# Note that we've added two derivatives together, 10 + 5, which is not the\n",
    "# correct derivative for y = 10 * x or y = 5 * x!\n",
    "assert some_input.grad == 15\n",
    "\n",
    "print(f\"{some_input.grad=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea5ab0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Because PyTorch will either throw an error on a given backwards call, or it'll\n",
    "# accumulate gradients when you potentially don't want that to happen, we\n",
    "# generally will want to reset gradients between calls to backward(). The\n",
    "# easiest way to do this is to set `.grad = None`. We'll see later how to do\n",
    "# this in a less manual fashion.\n",
    "\n",
    "some_input.grad = None\n",
    "\n",
    "yet_another_output = 5 * some_input\n",
    "\n",
    "yet_another_output.backward()\n",
    "\n",
    "# This time we get the correct gradient!\n",
    "assert some_input.grad == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e6248e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yep we still get the following error message:\n",
      "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Note that even after resetting a gradient, we still can't call backward again\n",
    "# on the same output. This has to do with the details of how PyTorch\n",
    "# automatically calculates derivatives. The exact details of why this is the\n",
    "# case are irrelevant at the moment (although they may become more apparent when\n",
    "# we implement backpropagation ourselves), but feel free to ask if you're\n",
    "# curious.\n",
    "\n",
    "some_input.grad = None\n",
    "\n",
    "try:\n",
    "    yet_another_output.backward()\n",
    "except RuntimeError as e:\n",
    "    print(f\"Yep we still get the following error message:\\n{str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf909c",
   "metadata": {},
   "source": [
    " $f(x_i, y_i) = \\sum_{0 <= i < 1000} x_i^2 + y_i^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc8c894",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result=array([[0.9161693 , 0.96571314],\n",
      "       [0.62499666, 1.2300433 ],\n",
      "       [0.4278946 , 0.8236524 ],\n",
      "       ...,\n",
      "       [0.5376427 , 1.2865753 ],\n",
      "       [1.2533709 , 1.2951387 ],\n",
      "       [0.7369081 , 1.3586906 ]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's drive home the notion that PyTorch's autodifferentiation handles\n",
    "# multidimensional tensors just fine, since this will often show up. We'll have\n",
    "# PyTorch calculate 2000 derivatives at once (i.e. calculate a single gradient\n",
    "# consisting of 2000 components)!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "one_thousand_random_points: Float[t.Tensor, \"1000 2\"] = t.rand(1000, 2, requires_grad=True)\n",
    "\n",
    "assert one_thousand_random_points.requires_grad\n",
    "\n",
    "# Using `one_thousand_random_points`, call $f(x_i, y_i) = sum_{0 <= i < 1000} x_i^2 + y_i^2$, (notice that\n",
    "# the thousand points are all (x, y) pairs because the second dimension is 2).\n",
    "\n",
    "def gradient_of_x_squared_plus_y_squared_plus_5_thousand_times() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Usually a Tensor will calculate its gradient as another Tensor, but here\n",
    "    we'll return a NumPy array.\n",
    "\n",
    "    We will calculate this for the function $f(x_i, y_i) = sum_{0 <= i < 1000} x_i^2 + y_i^2$\n",
    "\n",
    "    You should use `one_thousand_random_points` to generate the 1000 points\n",
    "    and then should ultimately return a 1000x2 NumPy array, representing a 1000x2 gradient.\n",
    "\n",
    "    Note to turn a PyTorch tensor into a NumPy array, call the .detach().numpy() method\n",
    "    on a tensor.\n",
    "    \"\"\"\n",
    "    points = one_thousand_random_points\n",
    "    # TODO: Implement this\n",
    "    # raise NotImplementedError()\n",
    "    f = t.sum(one_thousand_random_points ** 2)\n",
    "    f.backward()\n",
    "    return one_thousand_random_points.grad.detach().numpy()\n",
    "\n",
    "result = gradient_of_x_squared_plus_y_squared_plus_5_thousand_times()\n",
    "print(f\"{result=}\")\n",
    "assert_with_expect(expected=one_thousand_random_points[0][0] * 2, actual=result[0][0])\n",
    "assert_with_expect(expected=one_thousand_random_points[1][1] * 2, actual=result[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d97c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "# Recall that a higher-level way of thinking about a neural layer net is that it\n",
    "# is a general linear function with an added constant, followed by a non-linear\n",
    "# function. Let's begin by implementing application of a linear function.\n",
    "# Remember that a function from a vector space of dimension n to a vector space\n",
    "# of dimension m can be implemented as an m x n matrix.\n",
    "#\n",
    "# There is a major benefit in implementing a neural net layer this way: an\n",
    "# entire batch of inputs can be processed simultaneously! Instead of passing in\n",
    "# a single vector of size d_input, we're going to pass in a whole block of them\n",
    "# at once, in the form of a batch x d_input tensor.\n",
    "#\n",
    "# You should be able to write in this one or two lines without any iteration.\n",
    "# You can either use einops.einsum or you can use built-in PyTorch methods.\n",
    "\n",
    "def apply_linear_function_to_input(\n",
    "    linear_function: Float[t.Tensor, \"d_output d_input\"],\n",
    "    input_to_function: Float[t.Tensor, \"batch d_input\"],\n",
    ") -> Float[t.Tensor, \"batch d_output\"]:\n",
    "    # TODO: Implement this\n",
    "    # raise NotImplementedError()\n",
    "    return einops.einsum(linear_function, input_to_function, \\\n",
    "                         \"d_output d_input, batch d_input -> batch d_output\")\n",
    "\n",
    "# 3x2 matrix, i.e. f: R^2 -> R^3\n",
    "test_linear_function = t.tensor(\n",
    "    [\n",
    "        [1.0, 2.0],\n",
    "        [3.0, 4.0],\n",
    "        [5.0, 6.0],\n",
    "    ]\n",
    ")\n",
    "# A batch size of 4 vectors all combined together\n",
    "test_input = t.tensor(\n",
    "    [\n",
    "        [0.5, 0.6],\n",
    "        [0.3, 0.4],\n",
    "        [-2.0, -9.0],\n",
    "        [-8.0, 1.0],\n",
    "    ]\n",
    ")\n",
    "test_output = apply_linear_function_to_input(linear_function=test_linear_function, input_to_function=test_input)\n",
    "expected_output = t.tensor(\n",
    "    [\n",
    "        [1.7, 3.9, 6.1],\n",
    "        [1.1, 2.5, 3.9],\n",
    "        [-20, -42, -64],\n",
    "        [-6, -20, -34]\n",
    "    ]\n",
    ")\n",
    "\n",
    "assert_tensors_within_epsilon(\n",
    "    expected=expected_output,\n",
    "    actual=test_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5f76723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_input.grad=tensor([[24.6366, 25.4809]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# And as we expect, gradients flow through automatically.\n",
    "example_input = t.rand((1, 2), requires_grad=True)\n",
    "example_result = apply_linear_function_to_input(example_input, t.rand((50, 2))).sum()\n",
    "example_result.backward()\n",
    "print(f\"{example_input.grad=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d5c708",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Putting this together, we can create a three layer neural net consisting of\n",
    "# six tensors, instead of needing to create each neuron individually.\n",
    "\n",
    "@dataclass\n",
    "class ThreeLayerNeuralNet:\n",
    "    layer_0: Float[t.Tensor, \"d_output_0 d_input\"]\n",
    "    layer_0_bias: Float[t.Tensor, \"d_output_0\"]\n",
    "    layer_1: Float[t.Tensor, \"d_output_1 d_output_0\"]\n",
    "    layer_1_bias: Float[t.Tensor, \"d_output_1\"]\n",
    "    layer_2: Float[t.Tensor, \"d_output_2 d_output_1\"]\n",
    "    layer_2_bias: Float[t.Tensor, \"d_output_2\"]\n",
    "\n",
    "# Now that we have the class structure, let's create a way of actually\n",
    "# initializing the neural net.\n",
    "#\n",
    "# Ultimately we're going to be creating a neural net to recognize handwritten\n",
    "# digits, so it'll have an output of 10 digits.\n",
    "#\n",
    "# In our case we're going to create a very specific neural net. It's going to be\n",
    "# a series of layers going from an input of dimension 784 to 2000 to 400 and\n",
    "# finally to 10. That is:\n",
    "#\n",
    "# + d_input = 784\n",
    "# + d_output_0 = 2000\n",
    "# + d_output_1 = 400\n",
    "# + d_output_2 = 10\n",
    "#\n",
    "# 784 is because our images are of size 28x28. The intermediate dimensions of\n",
    "# 2000 and 400 in our hidden layers are chosen more or less arbitrarily. We'll\n",
    "# see some rules of thumb for sizing these layers later.\n",
    "#\n",
    "# Let's go ahead and implement that! We've provided the first\n",
    "# few lines of this, fill in the rest (making sure to call\n",
    "# ``.uniform_(-initial_bound, initial_bound`)).\n",
    "def initialize_new_three_layer_net() -> ThreeLayerNeuralNet:\n",
    "    \"\"\"\n",
    "    Initialize our net?\n",
    "    \"\"\"\n",
    "    # Since we have ReLU that clamps values to 0, having an initial set of\n",
    "    # weights that are all 0 can sometimes cause gradients to be stuck at 0 and\n",
    "    # never move. So we generally want to inject a little bit of randomness when\n",
    "    # initializing and move weights just a little bit away from 0.\n",
    "    #\n",
    "    # We also can't have these bounds be too big! Otherwise again ReLU may bite\n",
    "    # us and clamp us down to 0 if there's a sign change somewhere.\n",
    "    #\n",
    "    # This particular bound was chosen semi-randomly (I kind of pulled it out of\n",
    "    # a hat and verified that it worked). You'll see later a slightly more\n",
    "    # principled/standard way of choosing this bound.\n",
    "    initial_bound = 1 / 20\n",
    "    with t.no_grad():\n",
    "        neural_net = ThreeLayerNeuralNet(\n",
    "            # We're going to use usual matrix order of dimensions here. That is\n",
    "            # for a matrix mxn, that means we have n-dimensional input and\n",
    "            # m-dimensional output, so likewise here (300, 784) means\n",
    "            # 784-dimensional input and 300-dimensional output\n",
    "            layer_0 = t.zeros((2000, 784), requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
    "            layer_0_bias = t.zeros(2000, requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
    "            # TODO: Finish implementing \n",
    "            layer_1 = t.rand((400, 2000), requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
    "            layer_1_bias = t.rand(400, requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
    "            layer_2 = t.rand((10, 400), requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
    "            layer_2_bias = t.rand(10, requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
    "        )\n",
    "        return neural_net\n",
    "\n",
    "new_neural_net = initialize_new_three_layer_net()\n",
    "\n",
    "assert_with_expect(\n",
    "    expected=(400, 2000),\n",
    "    actual=new_neural_net.layer_1.shape,\n",
    ")\n",
    "assert_with_expect(\n",
    "    expected=(10, 400),\n",
    "    actual=new_neural_net.layer_2.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a4f06e4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# We'll need a version of ReLU that works with tensors of arbitrary size. Let's implement that:\n",
    "\n",
    "def tensor_relu(input_tensor: t.Tensor) -> t.Tensor:\n",
    "    # TODO: Implement this\n",
    "    # raise NotImplementedError()\n",
    "    zeroes = t.zeros(input_tensor.shape)\n",
    "    return t.max(zeroes, input_tensor)\n",
    "\n",
    "test_input = t.tensor([\n",
    "    [1.0, 2.0, -3.0],\n",
    "    [4.0, -5.0, 6.0],\n",
    "])\n",
    "assert_tensors_within_epsilon(\n",
    "    expected=t.tensor([\n",
    "        [1.0, 2.0, 0.0],\n",
    "        [4.0, 0.0, 6.0],\n",
    "    ]),\n",
    "    actual=tensor_relu(test_input)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00443206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now let's define a version of `forward` that works with tensors. Again, our\n",
    "# input tensor is a whole batch of inputs, not just a single input!\n",
    "#\n",
    "# Our last layer will use a softmax, which is a function that normalizes a\n",
    "# vector to be between 0 and 1 and to sum to 1. This helps with stability in\n",
    "# training and lets us interpret each of the 10 components in our output as a\n",
    "# probability. You can read\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html for\n",
    "# more details.\n",
    "\n",
    "def forward(x: Float[t.Tensor, \"batch d_input\"], neural_net: ThreeLayerNeuralNet) -> Float[t.Tensor, \"batch d_output\"]:\n",
    "    # TODO: Fill in the first two layers of this!\n",
    "    # raise NotImplementedError()\n",
    "    l_1 = tensor_relu(apply_linear_function_to_input(neural_net.layer_0, x) + neural_net.layer_0_bias)\n",
    "    l_2 = tensor_relu(apply_linear_function_to_input(neural_net.layer_1, l_1) + neural_net.layer_1_bias)\n",
    "    l_3 = apply_linear_function_to_input(neural_net.layer_2, l_2)\n",
    "    soft_3 = t.nn.functional.softmax(l_3 + neural_net.layer_2_bias, dim=1)\n",
    "    return soft_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5396f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_output=tensor([[0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660],\n",
      "        [0.0880, 0.0986, 0.0558, 0.1117, 0.1451, 0.1143, 0.1059, 0.1316, 0.0829,\n",
      "         0.0660]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_output = forward(neural_net=new_neural_net, x=t.ones((10, 784)))\n",
    "\n",
    "print(f\"{example_output=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bed65430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weren't able to calculate a gradient because of:\n",
      "grad can be implicitly created only for scalar outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Note that generally speaking we'll mainly be using scalar (i.e. 0-dimensional\n",
    "# tensor) outputs that we call .backward() on. This is not too much of a\n",
    "# limitation because almost always a loss function will output a scalar. There\n",
    "# are ways to deal with non-scalar outputs, but it's irrelevant to us at the\n",
    "# moment and for now we'll just point out that trying to do so will cause an\n",
    "# error.\n",
    "try:\n",
    "    # example_output is not a scalar!\n",
    "    example_output.backward()\n",
    "except RuntimeError as e:\n",
    "    print(f\"Weren't able to calculate a gradient because of:\\n{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18b28204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Notice now that we've turned example_output into a scalar, our call to\n",
    "# .backward() proceeds with no problem!\n",
    "example_scalar = example_output.sum()\n",
    "\n",
    "example_scalar.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbdffcc1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_neural_net.layer_0=tensor([[ 2.6665e-02,  6.0188e-03, -3.6897e-02,  ..., -2.9631e-03,\n",
      "          2.7440e-03,  2.2885e-02],\n",
      "        [ 1.5650e-02,  1.0060e-02, -7.6510e-03,  ...,  4.4135e-02,\n",
      "         -1.0004e-02,  4.1362e-02],\n",
      "        [ 4.7334e-02, -4.9868e-02,  2.3435e-03,  ..., -4.4880e-02,\n",
      "         -7.6023e-03, -8.5151e-03],\n",
      "        ...,\n",
      "        [-4.7405e-02,  3.4039e-02,  3.1174e-02,  ...,  2.7006e-02,\n",
      "         -4.7982e-02, -4.7940e-02],\n",
      "        [ 3.4604e-02, -4.6491e-02, -2.1544e-02,  ..., -1.7410e-02,\n",
      "          2.9455e-02, -3.1414e-02],\n",
      "        [ 2.2848e-02,  3.0233e-02, -3.8859e-02,  ...,  4.8118e-02,\n",
      "          4.6384e-05,  4.1248e-02]], requires_grad=True)\n",
      "new_neural_net.layer_0.grad=tensor([[ 2.1300e-09,  2.1300e-09,  2.1300e-09,  ...,  2.1300e-09,\n",
      "          2.1300e-09,  2.1300e-09],\n",
      "        [-1.2675e-09, -1.2675e-09, -1.2675e-09,  ..., -1.2675e-09,\n",
      "         -1.2675e-09, -1.2675e-09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 1.5127e-09,  1.5127e-09,  1.5127e-09,  ...,  1.5127e-09,\n",
      "          1.5127e-09,  1.5127e-09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.9000e-10,  4.9000e-10,  4.9000e-10,  ...,  4.9000e-10,\n",
      "          4.9000e-10,  4.9000e-10]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# And we can calculate the gradient of one of our neural net layers relative to\n",
    "# this scalar!\n",
    "\n",
    "print(f\"{new_neural_net.layer_0=}\")\n",
    "print(f\"{new_neural_net.layer_0.grad=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12966630",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# We'll need a few more pieces to actually be able to train our neural net.\n",
    "# \n",
    "# Remember how we mentioned that we need to make sure we reset gradients to\n",
    "# prevent gradient accumulation? Let's do that now.\n",
    "\n",
    "def zero_all_gradients(neural_net: ThreeLayerNeuralNet) -> None:\n",
    "    neural_net.layer_0.grad = None\n",
    "    neural_net.layer_0_bias.grad = None\n",
    "    # TODO: Finish implementing this for all the other layers in our neural net\n",
    "    # raise NotImplementedError()\n",
    "    neural_net.layer_1.grad = None\n",
    "    neural_net.layer_1_bias.grad = None\n",
    "    neural_net.layer_2.grad = None\n",
    "    neural_net.layer_2_bias.grad = None\n",
    "    \n",
    "\n",
    "\n",
    "# Now let's implement the simplest loss function out there, the mean squared\n",
    "# error: https://en.wikipedia.org/wiki/Mean_squared_error. This consists of\n",
    "# squaring the difference between every component of the two tensors and taking\n",
    "# their mean.\n",
    "\n",
    "def loss_function(\n",
    "    expected_outputs: Float[t.Tensor, \"batch d_output\"],\n",
    "    actual_outputs: Float[t.Tensor, \"batch d_output\"],\n",
    ") -> Float[t.Tensor, \"\"]:\n",
    "    # TODO: Implement this\n",
    "    # raise NotImplementedError()\n",
    "    assert len(expected_outputs) == len(actual_outputs)\n",
    "    res_diff = (expected_outputs-actual_outputs) ** 2\n",
    "    return t.mean(res_diff)\n",
    "\n",
    "\n",
    "# Now we can use derivatives/gradients to iteratively nudge an input tensor\n",
    "# towards a minimum with respect to a loss!\n",
    "\n",
    "def nudge_tensor_towards_minimum(x: t.Tensor, learning_rate: float) -> None:\n",
    "    # We need to do t.no_grad() here because we will be directly modifying x\n",
    "    # using x's gradients and we don't want to recompute x's gradients, since\n",
    "    # the only thing that should affect x's gradients is the loss function, not\n",
    "    # our adjustment to x.\n",
    "    with t.no_grad():\n",
    "        # TODO: Implement this\n",
    "        # raise NotImplementedError()\n",
    "        x -= x.grad * learning_rate\n",
    "\n",
    "\n",
    "\n",
    "example_tensor = t.tensor([1.1, 2.2, 3.3])\n",
    "example_tensor.grad = t.tensor([0.1, 0.1, 0.1])\n",
    "nudge_tensor_towards_minimum(example_tensor, learning_rate=2)\n",
    "assert not t.allclose(example_tensor, t.tensor([1.1, 2.2, 3.3])), \\\n",
    "    f\"It doesn't appear that nudge_tensor_towards_minimum actually modifies your tensor! Make sure that you are using -= and not x = x - ...\"\n",
    "assert_tensors_within_epsilon(expected=t.tensor([0.9, 2.0, 3.1]), actual=example_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "229163d8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Finally we put all this together in a function that performs one iteration of\n",
    "# tuning the weights of neural nets in training.\n",
    "#\n",
    "# This function will do the following steps:\n",
    "#\n",
    "# 1. Zero all our gradients (using `zero_all_gradients``)\n",
    "# 2. Calculate the outputs our neural net produces (using `forward`)\n",
    "# 3. Compare those outputs against `expected_outputs` to calculate our loss\n",
    "#    using `loss_function`\n",
    "# 4. Adjust our neural net weights\n",
    "#\n",
    "# Reminder: remember to call `.backward()` on the appropriate function!\n",
    "#\n",
    "# This function is hard to write good test cases for, so before you proceed,\n",
    "# take a look at the solutions and make sure that your implementation is\n",
    "# equivalent (as well as the implementations of `forward`, `loss_function` and\n",
    "# `nudge_tensor_towards_minimum`)\n",
    "\n",
    "def tune_weights_once(\n",
    "    neural_net: ThreeLayerNeuralNet,\n",
    "    inputs: Float[t.Tensor, \"batch d_input\"],\n",
    "    expected_outputs: Float[t.Tensor, \"batch d_output\"], \n",
    "    learning_rate: float,\n",
    ") -> None:\n",
    "    zero_all_gradients(neural_net)\n",
    "    # TODO: Fill in the rest\n",
    "    # raise NotImplementedError()\n",
    "    actual_outputs = forward(inputs, neural_net)\n",
    "    rmse = loss_function(expected_outputs, actual_outputs)\n",
    "    rmse.backward()\n",
    "    # nudge_tensor_towards_minimum(rmse, learning_rate)\n",
    "    nudge_tensor_towards_minimum(neural_net.layer_0, learning_rate)\n",
    "    nudge_tensor_towards_minimum(neural_net.layer_0_bias, learning_rate)\n",
    "    nudge_tensor_towards_minimum(neural_net.layer_1, learning_rate)\n",
    "    nudge_tensor_towards_minimum(neural_net.layer_1_bias, learning_rate)\n",
    "    nudge_tensor_towards_minimum(neural_net.layer_2, learning_rate)\n",
    "    nudge_tensor_towards_minimum(neural_net.layer_2_bias, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb031deb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now we can actually train our neural net!\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(\n",
    "    neural_net: ThreeLayerNeuralNet,\n",
    "    inputs: t.Tensor,\n",
    "    expected_outputs: t.Tensor,\n",
    "    learning_rate: float,\n",
    "    number_of_iterations: int,\n",
    ") -> None:\n",
    "    # print(\"expected \", expected_outputs.shape)\n",
    "    # print(\"actual \", actual_outputs.shape)\n",
    "    print(f\"Initial loss was {loss_function(expected_outputs=expected_outputs, actual_outputs=forward(x=inputs, neural_net=neural_net))}\")\n",
    "    for _ in tqdm(range(number_of_iterations)):\n",
    "        tune_weights_once(neural_net, inputs, expected_outputs, learning_rate)\n",
    "    print(f\"Final loss was {loss_function(expected_outputs=expected_outputs, actual_outputs=forward(x=inputs, neural_net=neural_net))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6417c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eef23fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = MNIST(root=\"data\", download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6a78d8f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is meant to express this numeral: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b9109dafc0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img, label = dataset[0]\n",
    "\n",
    "print(f\"This image is meant to express this numeral: {label}\")\n",
    "plt.imshow(img.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fab27718",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Before we can run training, there's one last thing we have to do: our images\n",
    "# come labeled with what digit they're supposed to represent, but that's a\n",
    "# single number, whereas our neural net outputs 10 components.\n",
    "#\n",
    "# That means we have to translate a number into a 10-component vector. E.g. if 2\n",
    "# is the correct answer, the ideal answer from our neural net would be [0, 0, 1,\n",
    "# 0, 0, 0, 0, 0, 0, 0].\n",
    "#\n",
    "# Doing this translation is called a \"one-hot encoding.\" Let's implement it!\n",
    "\n",
    "def one_hot_encoding(i: int, num_classes: int) -> t.Tensor:\n",
    "    # TODO: Implement this!\n",
    "    # raise NotImplementedError()\n",
    "    result = t.zeros([num_classes])\n",
    "    result[i] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "assert_tensors_within_epsilon(\n",
    "    expected=t.tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
    "    actual=one_hot_encoding(2, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22fbcba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We also need to flatten an image down to a flat vector to make it suitable for\n",
    "# our neural net to ingest.\n",
    "\n",
    "def make_img_1d(imgs: t.Tensor) -> t.Tensor:\n",
    "    return einops.rearrange(imgs, '... h w -> ... (h w)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df16dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is an inefficient way of getting data from a dataset. We'll see later how\n",
    "# to do this more efficiently, but for now this suffices to demonstrate the\n",
    "# logic of how we're using our one-hot encoding and 1d flattening.\n",
    "\n",
    "training_imgs = []\n",
    "expected_outputs_in_training = []\n",
    "non_training_imgs = []\n",
    "expected_outputs_in_non_training = []\n",
    "counter = 0\n",
    "total_imgs = 2000\n",
    "num_of_training_imgs = 1000\n",
    "for img, label in dataset:\n",
    "    if counter >= total_imgs:\n",
    "        break\n",
    "    if counter < num_of_training_imgs:\n",
    "        training_imgs.append(make_img_1d(img).squeeze())\n",
    "        expected_outputs_in_training.append(one_hot_encoding(label, num_classes=10))\n",
    "    else:\n",
    "        non_training_imgs.append(make_img_1d(img).squeeze())\n",
    "        expected_outputs_in_non_training.append(one_hot_encoding(label, num_classes=10))\n",
    "    counter += 1\n",
    "\n",
    "training_imgs = t.stack(training_imgs)\n",
    "expected_outputs_in_training = t.stack(expected_outputs_in_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85dc28fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_imgs.shape=torch.Size([1000, 784])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"{training_imgs.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d2d5d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected label: 0\n",
      "Model guessed this was: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Our neural net starts out with garbage predictions.\n",
    "\n",
    "non_training_img_idx = 0\n",
    "img_outside_of_training_dataset = non_training_imgs[non_training_img_idx]\n",
    "label = expected_outputs_in_non_training[non_training_img_idx].argmax()\n",
    "\n",
    "print(f\"Expected label: {label}\")\n",
    "plt.imshow(einops.rearrange(img_outside_of_training_dataset, '(h w) -> h w', h=28))\n",
    "\n",
    "model_all_guesses = forward(neural_net=new_neural_net, x=img_outside_of_training_dataset.unsqueeze(dim=0))\n",
    "model_guess_highest_prob = forward(neural_net=new_neural_net, x=img_outside_of_training_dataset.unsqueeze(dim=0)).argmax()\n",
    "\n",
    "print(f\"Model guessed this was: {model_guess_highest_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ccca92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss was 0.0900823101401329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 29.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss was 0.0022350302897393703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now let's train our neural net!\n",
    "train(\n",
    "    neural_net=new_neural_net,\n",
    "    inputs=training_imgs,\n",
    "    expected_outputs=expected_outputs_in_training,\n",
    "    # A learning rate of 2 is usually much too high, but we've made some sub-optimal choices in designing our \n",
    "    learning_rate=10,\n",
    "    number_of_iterations=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76d246d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected label: 0\n",
      "Model guessed this was: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# And let's try again\n",
    "\n",
    "print(f\"Expected label: {label}\")\n",
    "plt.imshow(einops.rearrange(img_outside_of_training_dataset, '(h w) -> h w', h=28))\n",
    "\n",
    "model_all_guesses = forward(neural_net=new_neural_net, x=img_outside_of_training_dataset.unsqueeze(dim=0))\n",
    "model_guess_highest_prob = forward(neural_net=new_neural_net, x=img_outside_of_training_dataset.unsqueeze(dim=0)).argmax()\n",
    "\n",
    "print(f\"Model guessed this was: {model_guess_highest_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fe773c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here's a demonstration of how we could write this using PyTorch entirely. In\n",
    "# two days you will have implemented every PyTorch function and class here from\n",
    "# scratch!\n",
    "\n",
    "class SimpleNeuralNet(t.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.implementation = t.nn.Sequential(\n",
    "            t.nn.Linear(in_features=784, out_features=2000),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Linear(in_features=2000, out_features=400),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Linear(in_features=400, out_features=10),\n",
    "            t.nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, t: t.Tensor):\n",
    "        return self.implementation(t)\n",
    "\n",
    "\n",
    "def train(model: SimpleNeuralNet, epochs: int, lr: int):\n",
    "    optimizer = t.optim.SGD(model.parameters(), lr=lr)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        output = model(training_imgs)\n",
    "        # For those who are confused why we use MSE loss here for a\n",
    "        # classification task, see https://arxiv.org/abs/2006.07322\n",
    "        loss = t.nn.functional.mse_loss(output, expected_outputs_in_training)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch == 0:\n",
    "            print(f\"Initial loss: {loss=}\")\n",
    "        elif epoch == epochs - 1:\n",
    "            print(f\"Final loss: {loss=}\")\n",
    "\n",
    "model = SimpleNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "552c34b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: loss=tensor(0.0900, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 34.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: loss=tensor(0.0056, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(model, epochs=100, lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "446c1be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected label: 0\n",
      "Model guessed this was: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Let's look at an image that wasn't part of the training data\n",
    "\n",
    "non_training_img_idx = 0\n",
    "img_outside_of_training_dataset = non_training_imgs[non_training_img_idx]\n",
    "label = expected_outputs_in_non_training[non_training_img_idx].argmax()\n",
    "\n",
    "print(f\"Expected label: {label}\")\n",
    "plt.imshow(einops.rearrange(img_outside_of_training_dataset, '(h w) -> h w', h=28))\n",
    "\n",
    "model_all_guesses = model(img_outside_of_training_dataset)\n",
    "model_guess_highest_prob = model(img_outside_of_training_dataset).argmax()\n",
    "\n",
    "print(f\"Model guessed this was: {model_guess_highest_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea68468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# As a bonus exercise try to make your model display what image it thinks is the\n",
    "# \"most like an 8.\" That is try to figure out some way of creating an image that\n",
    "# the model returns a very high value for in the 7th index of its output.\n",
    "\n",
    "# I'm going to let you try to figure this one out without as much handholding!\n",
    "# As a hint, think about whether you can use gradient descent (or perhaps\n",
    "# ascent!) on something that isn't the model weights."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "nnexercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
